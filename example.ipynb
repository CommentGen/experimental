{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "0dc6150ed5ea0a35b295a811b12fee934231f15f2f6934b2d59ca9bf83eeef91"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModel, EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_system_health_check():\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    print('Found {cnt} GPUs.'.format(cnt=len(gpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1 GPUs.\n"
     ]
    }
   ],
   "source": [
    "run_system_health_check()"
   ]
  },
  {
   "source": [
    "# Phase 1: have the transformers example running"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello_world_tranformers_example():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "    inputs = tokenizer(\"Hello world!\", return_tensors=\"tf\")\n",
    "    outputs = model(**inputs)\n",
    "    print(outputs)"
   ]
  },
  {
   "source": [
    "# Phase 2: modify the transformers example to run in Chinese"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_transformers_example():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "    model = TFAutoModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "    inputs = tokenizer(\"你好!\", return_tensors=\"tf\")\n",
    "    outputs = model(**inputs)\n",
    "    print(outputs)"
   ]
  },
  {
   "source": [
    "# Phase 3: modify the transformers example to run as a text generator (English first)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_generation_with_bert_example():\n",
    "    sentence_fuser = EncoderDecoderModel.from_pretrained(\"google/roberta2roberta_L-24_discofuse\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/roberta2roberta_L-24_discofuse\")\n",
    "    summary_text = 'This is the first sentence.'\n",
    "    input_ids = tokenizer(summary_text, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "    outputs = sentence_fuser.generate(input_ids)\n",
    "    print('Generated {cnt} pieces.'.format(cnt=len(outputs)))\n",
    "    print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "source": [
    "# Phase 4: train text generator with custom text corpus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Phase 5: train text generator with Chinese text corpus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Phase 6: use Chinese in the text generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "TODO(tianhaoz95): think about the next steps to build a comment generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# The main program to test things out"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generated 1 pieces.\nThis is the first sentence. In fact, the is\n"
     ]
    }
   ],
   "source": [
    "# hello_world_tranformers_example()\n",
    "# chinese_transformers_example()\n",
    "text_generation_with_bert_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}